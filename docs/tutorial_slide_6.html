<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>第６章 重回帰分析の基本</title>
    <meta charset="utf-8" />
    <meta name="author" content="阿部景太" />
    <meta name="date" content="2023-04-05" />
    <script src="libs/header-attrs-2.20/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/ninjutsu.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/useR-fonts.css" rel="stylesheet" />
    <script src="libs/kePrint-0.0.1/kePrint.js"></script>
    <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# 第６章 重回帰分析の基本
## <small>A tutorial for regression analysis</small>
### 阿部景太
### 2023-04-05

---


&lt;style type="text/css"&gt;
.remark-slide-content {
    font-size: 30px;
    font-family: "メイリオ" ;
    padding: 1em 4em 1em 4em;
}
&lt;/style&gt;



# 単回帰モデル

データを用いて推定する（観測番号がつく）

$$
 Y_i = \beta_0 + \beta_1 X_i + U_i
$$

`\(\beta_0,\beta_1\)` : 回帰パラメター  
`\(Y\)` ：被説明変数/従属変数  
`\(X\)` ：説明変数/独立変数  


---

# 外的条件が揃っていない場合

外的条件 `\(C\)` が揃っていない場合、確率変数 `\(C\)` が取りうる値 `\(c\)` を使って揃える。

$$
  E[Y|X=1, C=c] - E[Y|X=0, C=c]
$$

政策を示す変数(政策変数)と成果を示す変数(成果変数)の関係のみをモデル化するものが**単回帰分析**。外的条件を共変量で制御しながら因果効果を探る回帰分析を**重回帰分析**と呼ぶ。


---

# 回帰分析

**回帰分析**は、成果変数の期待値 `\(E[Y|X]\)` を説明変数の関数として**モデル化**

$$
 E[Y|X,C] = f(X,C)
$$

---

# 外的条件

単回帰モデルを推定するときに、 `\(E[U|X]=E[U]\)` が成り立っているのか？

**例**：

- 朝ごはんを食べることがテストの点数に効果を与えるのか？
- 家庭の所得という外的条件
  - どういう可能性があるか？

---

# 回帰分析：重回帰モデル

単回帰モデルは、政策変数の実現値で条件付けした成果変数の期待値を次のようにモデル化する

$$
  E[Y|X,C] = \beta_0 + \beta_1 X + \beta_2 C
$$

誤差項をつけた重回帰モデル（母集団モデル）

$$
 Y = \beta_0 + \beta_1 X + \beta_2 C + U
$$

---

# 重回帰モデル

重回帰モデルは変数が一つと限らない

$$
  Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_k X_k+ U
$$

---

# Ceteris Paribus

社会は複雑→様々な条件が、入り組んでいる

外的条件を揃えることで、興味のある変数の効果を見る

**Ceteris paribus**: 「他の条件を一定として」


---

# 例6.1 ミンサー方程式

教育の収益率：就学年数を伸ばすことによる所得の増加率

$$
 \ln賃金_i = \beta_0 + \beta_1 修学年数_i + U_i
$$
--

高卒20年のベテランと大卒1年目を比較したらどちらの賃金が高いか？

$$
 \ln賃金_i = \beta_0 + \beta_1 修学年数_i + \beta_2 就業可能年数_i + \beta_3 就業可能年数_i^2 + U_i
$$

---

# 重回帰分析のイメージ

&lt;img src="figs/multmarg.png" width="400px" /&gt;


---

# 重回帰分析の推定

モーメント条件（もしくは最小化問題の1階条件）は `\(k+1\)` 本の方程式

$$
 E[X_1U]=0, E[X_2U]=0,\ldots,E[X_kU]=0,E[U]=0
$$

---

### 例6.2：教育の収益率の推定


```r
dat_income = read_csv("../data/tanaka_data/csv/6_1_income.csv")
rei6.2 = lm(lincome ~ yeduc + exper + exper2,dat_income); summary(rei6.2)
```

```
## 
## Call:
## lm(formula = lincome ~ yeduc + exper + exper2, data = dat_income)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.0389 -0.3214  0.1681  0.5124  2.1326 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.4855019  0.1107823   22.44   &lt;2e-16 ***
## yeduc        0.1175467  0.0070603   16.65   &lt;2e-16 ***
## exper        0.1961736  0.0074935   26.18   &lt;2e-16 ***
## exper2      -0.0063811  0.0003162  -20.18   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.7983 on 4295 degrees of freedom
## Multiple R-squared:  0.2066,	Adjusted R-squared:  0.206 
## F-statistic: 372.8 on 3 and 4295 DF,  p-value: &lt; 2.2e-16
```

---

# 自由度調整済み決定係数

決定係数 `\(R\)` : `\(X\)` の数が多いと、 `\(R\)` が大きくなる

$$
 R^2 = 1- \frac{\sum \hat{u}_i}{\sum (y_i - \bar{y})^2}
$$


**自由度調整済み決定係数**: 説明変数を増やすだけでは `\(R^2_a\)` は小さくなる

$$
 R^2_a = \frac{(1-R^2)(n-1)}{n-k-1}
$$

---
 
### 例6.3 教育の収益率の推定における `\(R^2\)` と `\(R^2_a\)`


```
## 
## Call:
## lm(formula = lincome ~ yeduc + exper + exper2, data = dat_income)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.0389 -0.3214  0.1681  0.5124  2.1326 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.4855019  0.1107823   22.44   &lt;2e-16 ***
## yeduc        0.1175467  0.0070603   16.65   &lt;2e-16 ***
## exper        0.1961736  0.0074935   26.18   &lt;2e-16 ***
## exper2      -0.0063811  0.0003162  -20.18   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.7983 on 4295 degrees of freedom
## Multiple R-squared:  0.2066,	Adjusted R-squared:  0.206 
## F-statistic: 372.8 on 3 and 4295 DF,  p-value: &lt; 2.2e-16
```


---

# 不偏性のための4つの仮定

1. **真のモデル** : 母集団分布において、確率変数 `\((Y,X_1,\cdots,X_k,U)\)` の間には次のような関係がある: `\(Y=\beta_0 + \beta_1X_1+\cdots+\beta_kX_k+U\)`

2. **無作為抽出** : 母集団から標本サイズ `\(n\)` の無作為抽出標本 `\(\{(x_{1i},\ldots,x_{ki},y_i)\}\)`が得られる

3. **平均独立** : `\(E[U|X_1,\ldots,X_k] = 0\)`

4. **識別条件** : 説明 `\(X\)` に変動があり、完全な*共線関係*がない

---

# 共線関係

ある説明変数が別の説明変数を完全に決定してしまう関係

- 男性ダミー変数 (男=1, 女性=0)と、女性ダミー変数（男=0, 女=1)
- ある変数のa倍

**多重共線性** (Multicollinearity)

説明変数同士の相関が高すぎると、うまくパラメターを推定できない問題

- 船の長さと船のトン数

---

# 欠落変数バイアス

真のモデルが

$$
 Y=\beta_0 + \beta_1X + \beta_2C + U
$$

なのに、単回帰モデルを推定してしまったら？

$$
  Y=\beta_0 + \beta_1X + V
$$

---

# 欠落変数バイアス (2)

この時、誤差項に見える `\(V\)` は実は `\(V=\beta_2C+U\)`

外的条件 `\(C\)` と `\(X\)` は関係があるので

$$
 C=\gamma_0 + \gamma_1X+U_c
$$
というモデルでは、 `\(\gamma_1\)` はゼロではない数値となる

例：朝ごはんを食べる家庭 `\(X\)` ほど、 家庭所得が高い `\(C\)`

---

# 欠落変数バイアス (3)

最小二乗推定量は、

$$
 \hat{\beta_1} = \frac{\frac{1}{n}\sum(x_i-\bar{x})(y_i-\bar{y})}{\frac{1}{n}\sum(x_i-\bar{x})^2}
$$

だが、真のモデルは `\(Y=\beta_0 + \beta_1X + \beta_2C + U\)`  なので、代入してして期待値を取ると

$$
 E[\hat{\beta}_1] = \beta_1 + \beta_2\gamma_1
$$

つまりどういうことか？

---

### 例6.4 親の教育水準が子供の就学年数に与える影響




```r
rei6.4.1 = lm(yeduc~mocograd,dat6_2_yeduc); summary(rei6.4.1 )
```

```
## 
## Call:
## lm(formula = yeduc ~ mocograd, data = dat6_2_yeduc)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.8550 -0.8550  0.1450  0.9337  4.1450 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 13.85500    0.02208  627.40   &lt;2e-16 ***
## mocograd     1.21128    0.07454   16.25   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.326 on 3952 degrees of freedom
## Multiple R-squared:  0.06263,	Adjusted R-squared:  0.06239 
## F-statistic:   264 on 1 and 3952 DF,  p-value: &lt; 2.2e-16
```

---

### 例6.4 親の教育水準が子供の就学年数に与える影響 (2)



```r
rei6.4.2 = lm(yeduc~mocograd+pacograd,dat6_2_yeduc); summary(rei6.4.2)
```

```
## 
## Call:
## lm(formula = yeduc ~ mocograd + pacograd, data = dat6_2_yeduc)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.5946 -1.0946 -0.0946  0.9054  4.4054 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 13.59462    0.02352 578.020  &lt; 2e-16 ***
## mocograd     0.49701    0.07630   6.514 8.23e-11 ***
## pacograd     1.10886    0.04751  23.339  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.243 on 3951 degrees of freedom
## Multiple R-squared:  0.1762,	Adjusted R-squared:  0.1758 
## F-statistic: 422.5 on 2 and 3951 DF,  p-value: &lt; 2.2e-16
```

---


```r
modelsummary::msummary(list(rei6.4.1,rei6.4.2), statistic =NULL,
                       gof_omit = 'Log.Lik.|AIC|BIC|F')
```

&lt;table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;   &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Model 1 &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Model 2 &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 13.855 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 13.595 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; mocograd &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.211 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.497 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;box-shadow: 0px 1px"&gt; pacograd &lt;/td&gt;
   &lt;td style="text-align:center;box-shadow: 0px 1px"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;box-shadow: 0px 1px"&gt; 1.109 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Num.Obs. &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 3954 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 3954 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; R2 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.063 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.176 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; R2 Adj. &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.062 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.176 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; RMSE &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.33 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.24 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---


```r
cor(dat6_2_yeduc)
```

```
##           mocograd  pacograd     yeduc
## mocograd 1.0000000 0.4011056 0.2502512
## pacograd 0.4011056 1.0000000 0.4090889
## yeduc    0.2502512 0.4090889 1.0000000
```

---

# 分散均一の仮定


.pull-left[

![](tutorial_slide_6_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;


]

.pull-right[

![](tutorial_slide_6_files/figure-html/unnamed-chunk-10-1.png)&lt;!-- --&gt;


]


---

# 分散均一性の仮定

Xに関わらず分散が誤差項の分散が一定と仮定する

$$
 V[U|X_1,\ldots,X_k] = V[U] = s^2
$$

---

# 最小二乗推定量の分散

 `\(j\)` 番目の変数の係数の推定量


$$
 V[\hat{\beta_j}|x_{11},\ldots,x_{k1},\ldots,x_{1n},\ldots,x_{kn}]=\frac{s^2}{\sum (x_{ji}-\bar{x}_j)^2(1-R_j^2)}
$$

 `\(R_j^2\)` は `\(X_j\)` をその他すべての説明変数と切片で回帰したときの決定係数
 
$$
 X_j = \gamma_0 + \gamma_1 X_1 + \cdots + \gamma_{j-1} X_{j-1}+\gamma_{j+1} X_{j+1} + \cdots + \gamma_{k}X_{k} +U_{j}
$$

今は「そういうもの」という理解でよい。
問題は、どういう構造をしていてどういう関係があるか？

---

# 最小二乗推定量の分散 (2)

- 誤差分散 `\(s^2\)` が大きいと、推定量の分散も大きくなる

- `\(x_j\)` の総変動が大きいと、分散が小さくなる

- 決定係数 `\(R_j\)` が大きいと、分散が大きくなる
  - 完全共線関係だと、分母がゼロ→分散が無限？
  - 多重共線性があると、分散が非常に大きくなる
  
---

# 最小二乗推定量の分散 (3)

誤差項の分散 `\(s^2\)` は単回帰と同様に残差を推定値として推定する

$$
 \hat{s}^2 = \frac{1}{n-k-1}\sum\hat{u}^2_i
$$

$$
\frac{1}{n-k-1}\sum(y_i - \hat{\beta}_0 - \hat{\beta}_1 x_{1i}-\cdots-\hat{\beta}_k x_{ki})^2
$$

---

# OLS is BLUE

最小二乗法(OLS: Ordinary Least Square)はBLUE

**B**est **L**inear **U**nbiased **E**stimator

つまり最良線形不偏推定量

最良とは最も効率的であるということ。

不偏性の4つの仮定と、誤差項均一の仮定が満たされていれば、回帰分析の中で最も効率的な線形の推定量であることが、ガウス=マルコフ定理という定理で証明されている

---

# 検定

推定はできるが、実際に推定された数値が統計的にどれほど信頼できるのか？

**仮説検定**を行って、推定されたパラメターを評価する

---

# 回帰パラメターの仮説検定

例：「朝ごはんを食べることはテストの点数に効果がない」という**帰無仮説**を建てる

$$
 Y=\beta_0 + \beta_1X+\beta_2C+U
$$

$$
 H_0: \beta_1 = 0
$$


この帰無仮説の下で、 `\(\hat{\beta_1}\)` が得られる確率が有意水準より低ければ、「効果がない」という仮説を棄却して、対立仮説である「効果がある」という結論を採択する

---

# パラメターの分布

パラメーターがどういう分布にしたがっているかを知る必要

ここで「誤差項が正規分布にしたがっている」という仮定を追加

$$
 U \sim N(0,s^2)
$$
すると、データで条件付けられた被説明変数 `\(Y\)` も正規分布に従う

$$
 Y|x \sim N(E[Y|x], s^2)
$$
$$
 = N(\beta_0 + \beta_1x_1+\ldots+\beta_kx_k, s^2)
$$

---

# パラメターの分布

最小二乗推定量は


$$
 \hat{\beta_1} = \sum\frac{\frac{1}{n}(x_i-\bar{x})}{\frac{1}{n}\sum(x_i-\bar{x})^2}(y_i-\bar{y}) = \sum w_i(y_i-\bar{y})
$$

つまり、 `\(y\)` の変動の加重平均であるので、 `\(\hat{\beta_1}\)` もまた正規分布に従う。（というのが直感的説明)

$$
 \hat{\beta}_1 \sim N(\beta_1, V[\hat{\beta}_1])
$$

---

# 標準化

パラメターの推定値を標準化することで、標準正規分布に変換し、検定を行うことができる

$$
 \frac{\hat{\beta}_1-\beta_1}{\sqrt{V[\hat{\beta}_1]}} \sim N(0,1)
$$
--
できる？本当に？

---

# 標準誤差

標準偏差(分散のルート)は分散がわからないので、未知

--

残差の分散から計算される標準誤差を使う

$$
 \frac{\hat{\beta}_1-\beta_1}{se(\hat{\beta}_1)}
$$
---

# t分布

帰無仮説 ( `\(\beta_1 = 0\)` )の下での検定では、以下の推定量（**統計検定量**) が用いられる。この検定量は自由度が `\(n-k-1\)` のt分布に従う

$$
  \frac{\hat{\beta}_1}{se(\hat{\beta}_1)} \sim t(n-k-1)
$$

---

# 古典的線形モデルの仮定

- 不偏性の4つの仮定

- 分散均一性の仮定

- 誤差項の正規性の仮定


---

### 例6.6 t検定


```
## 
## Call:
## lm(formula = lincome ~ yeduc + exper + exper2, data = dat_income)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.0389 -0.3214  0.1681  0.5124  2.1326 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.4855019  0.1107823   22.44   &lt;2e-16 ***
## yeduc        0.1175467  0.0070603   16.65   &lt;2e-16 ***
## exper        0.1961736  0.0074935   26.18   &lt;2e-16 ***
## exper2      -0.0063811  0.0003162  -20.18   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.7983 on 4295 degrees of freedom
## Multiple R-squared:  0.2066,	Adjusted R-squared:  0.206 
## F-statistic: 372.8 on 3 and 4295 DF,  p-value: &lt; 2.2e-16
```

---

# 複合仮説検定

一つ一つのパラメターは、t検定で検定できる（実際にはRなどがやってくれる）

複数のパラメターを同時に検定する場合は？

$$
 Y=\beta_0 + \beta_1X + \beta_2C_1 + \beta_3C_2 + U
$$

---

# 複合仮説検定 (2)

「家計所得 `\(C_1\)` と母親の学歴 `\(C_2\)` はともにテストの点数に寄与しない」

$$
 H_0 : \beta_2 = \beta_3 = 0
$$

対立仮説は

$$
 H_1 : \beta_2 \neq 0 または \beta_3 \neq 0
$$

---

# 複合仮説検定 (3)

考え方としては帰無仮説が真とした場合のモデル(R)と、元のモデル(UR)を比較すること

もし帰無仮説が真ならばモデル(R)は

$$
 Y = \beta_0 + \beta_1 X_i + U
$$
元のモデル(UR)は

$$
 Y = \beta_0 + \beta_1 X_i + \beta_2C_1 + \beta_3C_2 + U
$$
---

# 複合仮説検定 (4)

帰無仮説の下でのRモデルとURモデルの残差二乗和(SSR)の差に基づく統計量が、F分布に従うという性質を利用したものがF検定

$$
 \frac{(SSR_r-SSR_u)/q}{(SSR_r)/(n-k-1)} \sim F(q,n-k-1)
$$

---

# 例6.7 複合仮説検定


```
## Linear hypothesis test
## 
## Hypothesis:
## exper = 0
## exper2 = 0
## 
## Model 1: restricted model
## Model 2: lincome ~ yeduc + exper + exper2
## 
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1   4297 3373.8                                  
## 2   4295 2736.9  2    636.92 499.75 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

---

# 大標本理論

**一致性** : `\(\hat{\theta}_n \rightarrow_p \theta\)`

不偏性のための仮定よりも弱い仮定で一致性を持つことが証明できる


---

# 確認問題 6-1

微分してゼロと置く


---

# 実証分析 6-A

例6.2.と同じ


---

### 実証分析 6-B (1)


```r
ex6_B = lm(mocograd ~ pacograd, data=dat6_2_yeduc); summary(ex6_B)
```

```
## 
## Call:
## lm(formula = mocograd ~ pacograd, data = dat6_2_yeduc)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.26476 -0.01499 -0.01499 -0.01499  0.98501 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.014989   0.004898   3.061  0.00222 ** 
## pacograd    0.249768   0.009074  27.527  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.2593 on 3952 degrees of freedom
## Multiple R-squared:  0.1609,	Adjusted R-squared:  0.1607 
## F-statistic: 757.7 on 1 and 3952 DF,  p-value: &lt; 2.2e-16
```

---

### 実証分析 6-B (1)

残差をデータに統合


```r
dat6_2_yeduc$res = residuals(ex6_B)
```

---
### 実証分析 6-B (2)


```r
ex6_B_2 = lm(yeduc ~ res, data=dat6_2_yeduc); summary(ex6_B_2)
```

```
## 
## Call:
## lm(formula = yeduc ~ res, data = dat6_2_yeduc)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.9539 -0.9539  0.0461  1.0461  4.1703 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 13.96131    0.02169  643.72  &lt; 2e-16 ***
## res          0.49701    0.08368    5.94 3.11e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.364 on 3952 degrees of freedom
## Multiple R-squared:  0.008848,	Adjusted R-squared:  0.008597 
## F-statistic: 35.28 on 1 and 3952 DF,  p-value: 3.105e-09
```

---

### 実証分析 6-B (2)



```r
summary(rei6.4.2)
```

```
## 
## Call:
## lm(formula = yeduc ~ mocograd + pacograd, data = dat6_2_yeduc)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.5946 -1.0946 -0.0946  0.9054  4.4054 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 13.59462    0.02352 578.020  &lt; 2e-16 ***
## mocograd     0.49701    0.07630   6.514 8.23e-11 ***
## pacograd     1.10886    0.04751  23.339  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.243 on 3951 degrees of freedom
## Multiple R-squared:  0.1762,	Adjusted R-squared:  0.1758 
## F-statistic: 422.5 on 2 and 3951 DF,  p-value: &lt; 2.2e-16
```



---

### 実証分析 6-C (1)





```r
ex6_C = lm(happy_work ~ commute,dat6_3_happy_work); summary(ex6_C)
```

```
## 
## Call:
## lm(formula = happy_work ~ commute, data = dat6_3_happy_work)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.2255 -1.1395 -0.1395  0.8175  1.9465 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.2255101  0.0337480  65.945   &lt;2e-16 ***
## commute     -0.0014337  0.0008326  -1.722   0.0852 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.16 on 3602 degrees of freedom
## Multiple R-squared:  0.0008225,	Adjusted R-squared:  0.0005451 
## F-statistic: 2.965 on 1 and 3602 DF,  p-value: 0.08517
```

---

### 実証分析 6-C (2)


```r
ex6_C_2 = lm(happy_work ~ commute + income + yeduc,dat6_3_happy_work); summary(ex6_C_2)
```

```
## 
## Call:
## lm(formula = happy_work ~ commute + income + yeduc, data = dat6_3_happy_work)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.14965 -1.07076 -0.06573  0.85145  2.15422 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.836e+00  1.418e-01  12.949  &lt; 2e-16 ***
## commute     -2.491e-03  8.488e-04  -2.935  0.00335 ** 
## income       4.735e-04  8.759e-05   5.406 6.88e-08 ***
## yeduc        2.021e-02  1.046e-02   1.931  0.05350 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.154 on 3600 degrees of freedom
## Multiple R-squared:  0.01138,	Adjusted R-squared:  0.01056 
## F-statistic: 13.82 on 3 and 3600 DF,  p-value: 5.869e-09
```

---

### 実証分析 6-C (3)


```r
car::linearHypothesis(ex6_C_2, c("income=0","yeduc=0"))
```

```
## Linear hypothesis test
## 
## Hypothesis:
## income = 0
## yeduc = 0
## 
## Model 1: restricted model
## Model 2: happy_work ~ commute + income + yeduc
## 
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1   3602 4843.0                                  
## 2   3600 4791.8  2    51.189 19.229 4.935e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```


---

### 実証分析 6-D (1)




```r
ex6_D = lm(minshu ~ income,dat6_4_minshu); summary(ex6_D)
```

```
## 
## Call:
## lm(formula = minshu ~ income, data = dat6_4_minshu)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -49.427  -5.069   5.429   6.176  56.176 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 43.823682   0.423993 103.359   &lt;2e-16 ***
## income       0.002490   0.001199   2.078   0.0378 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 18.51 on 4216 degrees of freedom
## Multiple R-squared:  0.001023,	Adjusted R-squared:  0.000786 
## F-statistic: 4.317 on 1 and 4216 DF,  p-value: 0.03779
```
---

### 実証分析 6-D (2)


```r
ex6_D_2 = lm(minshu ~ income + yeduc,dat6_4_minshu); summary(ex6_D_2)
```

```
## 
## Call:
## lm(formula = minshu ~ income + yeduc, data = dat6_4_minshu)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -49.501  -5.462   5.408   6.578  57.483 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 39.302791   2.124906  18.496   &lt;2e-16 ***
## income       0.002002   0.001219   1.643    0.101    
## yeduc        0.334907   0.154250   2.171    0.030 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 18.5 on 4215 degrees of freedom
## Multiple R-squared:  0.002139,	Adjusted R-squared:  0.001665 
## F-statistic: 4.518 on 2 and 4215 DF,  p-value: 0.01097
```
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"coutIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
